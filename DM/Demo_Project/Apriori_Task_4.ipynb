{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1422b500",
   "metadata": {},
   "source": [
    "# Apriori Algorithm Implementation Assignment\n",
    "\n",
    "### Objective:\n",
    "You will implement the **Apriori algorithm** from scratch (i.e., without using any libraries like `mlxtend`) to find frequent itemsets and generate association rules.\n",
    "\n",
    "### Dataset:\n",
    "Use the [Online Retail Dataset](https://www.kaggle.com/datasets/vijayuv/onlineretail) from Kaggle. You can filter it for a specific country (e.g., `United Kingdom`) and time range to reduce size if needed.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85128a0",
   "metadata": {},
   "source": [
    "## Step 1: Data Preprocessing\n",
    "\n",
    "- Load the dataset\n",
    "- Remove rows with missing values\n",
    "- Filter out rows where `Quantity <= 0`\n",
    "- Convert Data into Basket Format\n",
    "\n",
    "ðŸ‘‰ **Implement code below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd66a2e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Description  ASSORTED COLOUR BIRD ORNAMENT  CREAM CUPID HEARTS COAT HANGER  \\\n",
      "InvoiceNo                                                                    \n",
      "536365                                   0                               1   \n",
      "536366                                   0                               0   \n",
      "536367                                   1                               0   \n",
      "\n",
      "Description  GLASS STAR FROSTED T-LIGHT HOLDER  HAND WARMER RED POLKA DOT  \\\n",
      "InvoiceNo                                                                   \n",
      "536365                                       1                          0   \n",
      "536366                                       0                          1   \n",
      "536367                                       0                          0   \n",
      "\n",
      "Description  HAND WARMER UNION JACK  KNITTED UNION FLAG HOT WATER BOTTLE  \\\n",
      "InvoiceNo                                                                  \n",
      "536365                            0                                    1   \n",
      "536366                            1                                    0   \n",
      "536367                            0                                    0   \n",
      "\n",
      "Description  RED WOOLLY HOTTIE WHITE HEART.  SET 7 BABUSHKA NESTING BOXES  \\\n",
      "InvoiceNo                                                                   \n",
      "536365                                    1                             1   \n",
      "536366                                    0                             0   \n",
      "536367                                    0                             0   \n",
      "\n",
      "Description  WHITE HANGING HEART T-LIGHT HOLDER  WHITE METAL LANTERN  \n",
      "InvoiceNo                                                             \n",
      "536365                                        1                    1  \n",
      "536366                                        0                    0  \n",
      "536367                                        0                    0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_2100\\633627972.py:13: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  basket = basket.applymap(lambda x: 1 if x > 0 else 0)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('OnlineRetail.csv', encoding='ISO-8859-1', nrows=10)\n",
    "\n",
    "# Preprocess as per the instructions above | We have already done in TASK 2\n",
    "df.dropna(how=\"any\", inplace=True)\n",
    "df = df[df['Quantity'] > 0]\n",
    "\n",
    "# Your Code Here\n",
    "# for Basket\n",
    "basket = df.groupby(['InvoiceNo', 'Description'])['Quantity'].sum().unstack().reset_index().fillna(0).set_index('InvoiceNo')\n",
    "basket = basket.applymap(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "print(basket.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a37baf6",
   "metadata": {},
   "source": [
    "## Step 2: Implement Apriori Algorithm\n",
    "Step-by-Step Procedure:\n",
    "1. Generate Frequent 1-Itemsets\n",
    "Count the frequency (support) of each individual item in the dataset.\n",
    "Keep only those with support â‰¥ min_support.\n",
    "â†’ Result is L1 (frequent 1-itemsets)\n",
    "2. Iterative Candidate Generation (k = 2 to n)\n",
    "While L(k-1) is not empty:\n",
    "a. Candidate Generation\n",
    "\n",
    "Generate candidate itemsets Ck of size k from L(k-1) using the Apriori property:\n",
    "Any (k-itemset) is only frequent if all of its (kâˆ’1)-subsets are frequent.\n",
    "b. Prune Candidates\n",
    "Eliminate candidates that have any (kâˆ’1)-subset not in L(k-1).\n",
    "c. Count Support\n",
    "For each transaction, count how many times each candidate in Ck appears.\n",
    "d. Generate Frequent Itemsets\n",
    "Form Lk by keeping candidates from Ck that meet the min_support.\n",
    "Repeat until Lk becomes empty.\n",
    "Implement the following functions:\n",
    "1. `get_frequent_itemsets(transactions, min_support)` - Returns frequent itemsets and their support\n",
    "2. `generate_candidates(prev_frequent_itemsets, k)` - Generates candidate itemsets of length `k`\n",
    "3. `calculate_support(transactions, candidates)` - Calculates the support count for each candidate\n",
    "\n",
    "**Write reusable functions** for each part of the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8f9310a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('A',): 4, ('B',): 4, ('C',): 4, ('A', 'B'): 3, ('A', 'C'): 3, ('B', 'C'): 3, ('A', 'B', 'C'): 2}\n"
     ]
    }
   ],
   "source": [
    "#---------------------------------------------------------------\n",
    "# Helper: check if subset is inside a set\n",
    "def is_subset(subset, superset):\n",
    "    for item in subset:\n",
    "        found = False\n",
    "        for s in superset:\n",
    "            if item == s:\n",
    "                found = True\n",
    "                break\n",
    "        if not found:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "# Helper: check if two lists are equal as sets\n",
    "def are_equal_sets(a, b):\n",
    "    if len(a) != len(b):\n",
    "        return False\n",
    "    for item in a:\n",
    "        if not is_subset([item], b):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "# Helper: generate all unique items\n",
    "def get_unique_items(transactions):\n",
    "    items = []\n",
    "    for t in transactions:\n",
    "        for x in t:\n",
    "            already = False\n",
    "            for i in items:\n",
    "                if i == x:\n",
    "                    already = True\n",
    "                    break\n",
    "            if not already:\n",
    "                items.append(x)\n",
    "    return [[i] for i in items]\n",
    "\n",
    "# Helper: generate k-combinations\n",
    "def generate_combinations(items, k):\n",
    "    result = []\n",
    "    def backtrack(start, path):\n",
    "        if len(path) == k:\n",
    "            result.append(path[:])\n",
    "            return\n",
    "        for idx in range(start, len(items)):\n",
    "            path.append(items[idx])\n",
    "            backtrack(idx + 1, path)\n",
    "            path.pop()\n",
    "\n",
    "    backtrack(0, [])\n",
    "    return result\n",
    "\n",
    "#---------------------------------------------------------------\n",
    "def calculate_support(transactions, candidates):\n",
    "    support_count = {}\n",
    "    for cand in candidates:\n",
    "        count = 0\n",
    "        for t in transactions:\n",
    "            if is_subset(cand, t):\n",
    "                count += 1\n",
    "        support_count[tuple(sorted(cand))] = count\n",
    "    return support_count\n",
    "\n",
    "#---------------------------------------------------------------\n",
    "def generate_candidates(prev_frequent_itemsets, k):\n",
    "    candidates = []\n",
    "    n = len(prev_frequent_itemsets)\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            union = []\n",
    "            for x in prev_frequent_itemsets[i]:\n",
    "                if not is_subset([x], union):\n",
    "                    union.append(x)\n",
    "            for y in prev_frequent_itemsets[j]:\n",
    "                if not is_subset([y], union):\n",
    "                    union.append(y)\n",
    "\n",
    "            # keep only if union size == k\n",
    "            if len(union) == k:\n",
    "                # prune step: all k-1 subsets must be frequent\n",
    "                subsets = generate_combinations(union, k - 1)\n",
    "                valid = True\n",
    "                for sub in subsets:\n",
    "                    found = False\n",
    "                    for freq in prev_frequent_itemsets:\n",
    "                        if are_equal_sets(sub, freq):\n",
    "                            found = True\n",
    "                            break\n",
    "                    if not found:\n",
    "                        valid = False\n",
    "                        break\n",
    "                if valid:\n",
    "                    # avoid duplicates\n",
    "                    already = False\n",
    "                    for c in candidates:\n",
    "                        if are_equal_sets(c, union):\n",
    "                            already = True\n",
    "                            break\n",
    "                    if not already:\n",
    "                        candidates.append(union)\n",
    "    return candidates\n",
    "\n",
    "#---------------------------------------------------------------\n",
    "def get_frequent_itemsets(transactions, min_support):\n",
    "    # Step 1: L1\n",
    "    single_items = get_unique_items(transactions)\n",
    "    support_data = {}\n",
    "    all_frequent_itemsets = {}\n",
    "\n",
    "    sup_counts = calculate_support(transactions, single_items)\n",
    "    current_frequent_itemsets = []\n",
    "    for item, count in sup_counts.items():\n",
    "        if count >= min_support:\n",
    "            current_frequent_itemsets.append(list(item))\n",
    "            support_data[item] = count\n",
    "            all_frequent_itemsets[item] = count\n",
    "\n",
    "    k = 2\n",
    "    while current_frequent_itemsets:\n",
    "        candidates = generate_candidates(current_frequent_itemsets, k)\n",
    "        sup_counts = calculate_support(transactions, candidates)\n",
    "\n",
    "        new_frequent = []\n",
    "        for item, count in sup_counts.items():\n",
    "            if count >= min_support:\n",
    "                new_frequent.append(list(item))\n",
    "                support_data[item] = count\n",
    "                all_frequent_itemsets[item] = count\n",
    "\n",
    "        current_frequent_itemsets = new_frequent\n",
    "        k += 1\n",
    "\n",
    "    return all_frequent_itemsets\n",
    "#---------------------------------------------------------------\n",
    "\n",
    "# Example Usage\n",
    "transactions = [\n",
    "    [\"A\", \"B\", \"C\"],\n",
    "    [\"A\", \"C\"],\n",
    "    [\"B\", \"C\"],\n",
    "    [\"A\", \"B\"],\n",
    "    [\"A\", \"B\", \"C\"]\n",
    "]\n",
    "\n",
    "min_support = 2\n",
    "print(get_frequent_itemsets(transactions, min_support))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb8c0fe",
   "metadata": {},
   "source": [
    "## Step 3: Generate Association Rules\n",
    "\n",
    "- Use frequent itemsets to generate association rules\n",
    "- For each rule `A => B`, calculate:\n",
    "  - **Support**\n",
    "  - **Confidence**\n",
    "- Only return rules that meet a minimum confidence threshold (e.g., 0.5)\n",
    "\n",
    "ðŸ‘‰ **Implement rule generation function below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97bc236e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'antecedent': ['A'], 'consequent': ['B'], 'support': 0.6, 'confidence': 0.75, 'lift': 0.9375}\n",
      "{'antecedent': ['B'], 'consequent': ['A'], 'support': 0.6, 'confidence': 0.75, 'lift': 0.9375}\n",
      "{'antecedent': ['A'], 'consequent': ['C'], 'support': 0.6, 'confidence': 0.75, 'lift': 0.9375}\n",
      "{'antecedent': ['C'], 'consequent': ['A'], 'support': 0.6, 'confidence': 0.75, 'lift': 0.9375}\n",
      "{'antecedent': ['B'], 'consequent': ['C'], 'support': 0.6, 'confidence': 0.75, 'lift': 0.9375}\n",
      "{'antecedent': ['C'], 'consequent': ['B'], 'support': 0.6, 'confidence': 0.75, 'lift': 0.9375}\n",
      "{'antecedent': ['A', 'B'], 'consequent': ['C'], 'support': 0.4, 'confidence': 0.6667, 'lift': 0.8333}\n",
      "{'antecedent': ['A', 'C'], 'consequent': ['B'], 'support': 0.4, 'confidence': 0.6667, 'lift': 0.8333}\n",
      "{'antecedent': ['B', 'C'], 'consequent': ['A'], 'support': 0.4, 'confidence': 0.6667, 'lift': 0.8333}\n"
     ]
    }
   ],
   "source": [
    "#---------------------------------------------------------------\n",
    "# Helper: check if subset is inside a set\n",
    "def is_subset(subset, superset):\n",
    "    for item in subset:\n",
    "        found = False\n",
    "        for s in superset:\n",
    "            if item == s:\n",
    "                found = True\n",
    "                break\n",
    "        if not found:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "# Helper: generate combinations of list elements\n",
    "def generate_combinations(items, k):\n",
    "    result = []\n",
    "\n",
    "    def backtrack(start, path):\n",
    "        if len(path) == k:\n",
    "            result.append(path[:])\n",
    "            return\n",
    "        for idx in range(start, len(items)):\n",
    "            path.append(items[idx])\n",
    "            backtrack(idx + 1, path)\n",
    "            path.pop()\n",
    "\n",
    "    backtrack(0, [])\n",
    "    return result\n",
    "\n",
    "#---------------------------------------------------------------\n",
    "def generate_association_rules(frequent_itemsets, transactions, min_confidence=0.5):\n",
    "    rules = []\n",
    "    total_transactions = len(transactions)\n",
    "\n",
    "    for itemset_tuple, support_count in frequent_itemsets.items():\n",
    "        itemset = list(itemset_tuple)\n",
    "\n",
    "        if len(itemset) >= 2:\n",
    "            for i in range(1, len(itemset)):\n",
    "                subsets = generate_combinations(itemset, i)\n",
    "                for left in subsets:\n",
    "                    right = []\n",
    "                    for x in itemset:\n",
    "                        if not is_subset([x], left):\n",
    "                            right.append(x)\n",
    "\n",
    "                    left_key = tuple(sorted(left))\n",
    "                    right_key = tuple(sorted(right))\n",
    "\n",
    "                    left_support_count = frequent_itemsets.get(left_key, 0)\n",
    "                    right_support_count = frequent_itemsets.get(right_key, 0)\n",
    "\n",
    "                    if left_support_count > 0 and right_support_count > 0:\n",
    "                        confidence = support_count / left_support_count\n",
    "                        support = support_count / total_transactions\n",
    "                        lift = confidence / (right_support_count / total_transactions)\n",
    "\n",
    "                        if confidence >= min_confidence:\n",
    "                            rules.append({\n",
    "                                'antecedent': left,\n",
    "                                'consequent': right,\n",
    "                                'support': round(support, 4),\n",
    "                                'confidence': round(confidence, 4),\n",
    "                                'lift': round(lift, 4)\n",
    "                            })\n",
    "    return rules\n",
    "\n",
    "\n",
    "#---------------------------------------------------------------\n",
    "\n",
    "# Example usage\n",
    "transactions = [\n",
    "    [\"A\", \"B\", \"C\"],\n",
    "    [\"A\", \"C\"],\n",
    "    [\"B\", \"C\"],\n",
    "    [\"A\", \"B\"],\n",
    "    [\"A\", \"B\", \"C\"]\n",
    "]\n",
    "\n",
    "# Get frequent itemsets first (from previous brute-force Apriori)\n",
    "min_support = 2\n",
    "frequent_itemsets = get_frequent_itemsets(transactions, min_support)\n",
    "\n",
    "rules = generate_association_rules(frequent_itemsets, transactions,min_confidence=0.6)\n",
    "for r in rules:\n",
    "    print(r)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf26889",
   "metadata": {},
   "source": [
    "## Step 4: Output and Visualize\n",
    "\n",
    "- Print top 10 frequent itemsets\n",
    "- Print top 10 association rules (by confidence or lift)\n",
    "\n",
    "ðŸ‘‰ **Output results below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3443a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Frequent Itemsets:\n",
      "1. Items: {'A'} | Support Count: 4\n",
      "2. Items: {'B'} | Support Count: 4\n",
      "3. Items: {'C'} | Support Count: 4\n",
      "4. Items: {'A', 'B'} | Support Count: 3\n",
      "5. Items: {'A', 'C'} | Support Count: 3\n",
      "6. Items: {'C', 'B'} | Support Count: 3\n",
      "7. Items: {'A', 'C', 'B'} | Support Count: 2\n",
      "\n",
      "Top 10 Association Rules (by Confidence):\n",
      "1. {'A'} -> {'B'} | Support: 0.6000 | Confidence: 0.7500 | Lift: 0.9375\n",
      "2. {'B'} -> {'A'} | Support: 0.6000 | Confidence: 0.7500 | Lift: 0.9375\n",
      "3. {'A'} -> {'C'} | Support: 0.6000 | Confidence: 0.7500 | Lift: 0.9375\n",
      "4. {'C'} -> {'A'} | Support: 0.6000 | Confidence: 0.7500 | Lift: 0.9375\n",
      "5. {'B'} -> {'C'} | Support: 0.6000 | Confidence: 0.7500 | Lift: 0.9375\n",
      "6. {'C'} -> {'B'} | Support: 0.6000 | Confidence: 0.7500 | Lift: 0.9375\n",
      "7. {'A', 'B'} -> {'C'} | Support: 0.4000 | Confidence: 0.6667 | Lift: 0.8333\n",
      "8. {'A', 'C'} -> {'B'} | Support: 0.4000 | Confidence: 0.6667 | Lift: 0.8333\n",
      "9. {'C', 'B'} -> {'A'} | Support: 0.4000 | Confidence: 0.6667 | Lift: 0.8333\n"
     ]
    }
   ],
   "source": [
    "# Print Top 10 Frequent Itemsets\n",
    "print(\"Top 10 Frequent Itemsets:\")\n",
    "# Example usage\n",
    "transactions = [\n",
    "    [\"A\", \"B\", \"C\"],\n",
    "    [\"A\", \"C\"],\n",
    "    [\"B\", \"C\"],\n",
    "    [\"A\", \"B\"],\n",
    "    [\"A\", \"B\", \"C\"]\n",
    "]\n",
    "# Get frequent itemsets first\n",
    "min_support = 2\n",
    "frequent_itemsets = get_frequent_itemsets(transactions, min_support)\n",
    "\n",
    "for idx, (itemset, support) in enumerate(sorted(frequent_itemsets.items(), key=lambda x: x[1], reverse=True)[:10], 1):\n",
    "    print(f\"{idx}. Items: {set(itemset)} | Support Count: {support}\")\n",
    "\n",
    "# Generate and sort rules by confidence\n",
    "sorted_rules = sorted(rules, key=lambda x: x['confidence'], reverse=True)\n",
    "\n",
    "# Print Top 10 Association Rules\n",
    "print(\"\\nTop 10 Association Rules (by Confidence):\")\n",
    "for idx, rule in enumerate(sorted_rules[:10], 1):\n",
    "    print(f\"{idx}. {set(rule['antecedent'])} -> {set(rule['consequent'])} \"\n",
    "          f\"| Support: {rule['support']:.4f} \"\n",
    "          f\"| Confidence: {rule['confidence']:.4f} \"\n",
    "          f\"| Lift: {rule['lift']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1f05e9-0778-4e7b-a70b-1e27e4d27000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Frequent Itemsets:\n"
     ]
    }
   ],
   "source": [
    "# Print Top 10 Frequent Itemsets\n",
    "print(\"Top 10 Frequent Itemsets:\")\n",
    "\n",
    "# Get frequent itemsets first\n",
    "min_support = 2\n",
    "frequent_itemsets = get_frequent_itemsets(basket, min_support)\n",
    "\n",
    "for idx, (itemset, support) in enumerate(sorted(frequent_itemsets.items(), key=lambda x: x[1], reverse=True)[:10], 1):\n",
    "    print(f\"{idx}. Items: {set(itemset)} | Support Count: {support}\")\n",
    "\n",
    "# Generate and sort rules by confidence\n",
    "sorted_rules = sorted(rules, key=lambda x: x['confidence'], reverse=True)\n",
    "\n",
    "# Print Top 10 Association Rules\n",
    "print(\"\\nTop 10 Association Rules (by Confidence):\")\n",
    "for idx, rule in enumerate(sorted_rules[:10], 1):\n",
    "    print(f\"{idx}. {set(rule['antecedent'])} -> {set(rule['consequent'])} \"\n",
    "          f\"| Support: {rule['support']:.4f} \"\n",
    "          f\"| Confidence: {rule['confidence']:.4f} \"\n",
    "          f\"| Lift: {rule['lift']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432abb5e-4a37-42d3-8c1e-7f7cb2f69de5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
